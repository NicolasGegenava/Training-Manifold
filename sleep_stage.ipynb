{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxngM1Rufboz"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Optional, Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "import timm\n",
        "import torchaudio\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    sample_rate: int = 16000\n",
        "    epoch_sec: int = 30\n",
        "    n_mels: int = 128\n",
        "    fmin: int = 20\n",
        "    fmax: int = 7600\n",
        "    hop_length: int = 160\n",
        "    win_length: int = 400\n",
        "    n_fft: int = 1024\n",
        "    top_db: Optional[int] = 80\n",
        "    spec_size: int = 224\n",
        "    num_classes: int = 4\n",
        "    vit_name: str = \"vit_base_patch16_224\"\n",
        "    vit_drop_rate: float = 0.1\n",
        "    vit_drop_path_rate: float = 0.1\n",
        "    train_batch_size: int = 32\n",
        "    val_batch_size: int = 48\n",
        "    lr: float = 2e-4\n",
        "    weight_decay: float = 1e-4\n",
        "    warmup_epochs: int = 2\n",
        "    epochs: int = 25\n",
        "    mixup_alpha: float = 0.0\n",
        "    spec_aug_freq_masks: int = 2\n",
        "    spec_aug_time_masks: int = 2\n",
        "    spec_aug_freq_width: int = 16\n",
        "    spec_aug_time_width: int = 32\n",
        "    label_smoothing: float = 0.05\n",
        "    num_workers: int = 4\n",
        "    seed: int = 42\n",
        "    class_names: List[str] = None\n",
        "\n",
        "\n",
        "DEFAULT_CLASS_NAMES_4 = [\"Wake\", \"Light\", \"Deep\", \"REM\"]\n",
        "DEFAULT_CLASS_NAMES_5 = [\"Wake\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
        "\n",
        "\n",
        "def set_seed(seed: int) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "c-NcuK7pfhVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_audio(path: str, target_sr: int) -> np.ndarray:\n",
        "    if TORCHAUDIO_AVAILABLE:\n",
        "        try:\n",
        "            wav, sr = torchaudio.load(path)\n",
        "            wav = wav.mean(0, keepdim=False).numpy()\n",
        "        except Exception:\n",
        "            wav, sr = sf.read(path, always_2d=False)\n",
        "            if wav.ndim == 2:\n",
        "                wav = wav.mean(axis=1)\n",
        "    else:\n",
        "        wav, sr = sf.read(path, always_2d=False)\n",
        "        if wav.ndim == 2:\n",
        "            wav = wav.mean(axis=1)\n",
        "\n",
        "    if sr != target_sr:\n",
        "        wav = librosa.resample(wav, orig_sr=sr, target_sr=target_sr, res_type=\"kaiser_fast\")\n",
        "        sr = target_sr\n",
        "\n",
        "    return wav.astype(np.float32)"
      ],
      "metadata": {
        "id": "_Bc15DQ9fjEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ensure_length_seconds(wav: np.ndarray, sr: int, sec: int) -> np.ndarray:\n",
        "    target_len = sec * sr\n",
        "    if len(wav) == target_len:\n",
        "        return wav\n",
        "    if len(wav) > target_len:\n",
        "        return wav[:target_len]\n",
        "    # pad by reflection to avoid hard edges\n",
        "    pad_len = target_len - len(wav)\n",
        "    if pad_len <= 0:\n",
        "        return wav\n",
        "    left = pad_len // 2\n",
        "    right = pad_len - left\n",
        "    wav = np.pad(wav, (left, right), mode=\"reflect\")\n",
        "    return wav"
      ],
      "metadata": {
        "id": "VZ1ZFFRofndV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wav_to_logmel(\n",
        "    wav: np.ndarray,\n",
        "    sr: int,\n",
        "    n_mels: int,\n",
        "    n_fft: int,\n",
        "    hop_length: int,\n",
        "    win_length: int,\n",
        "    fmin: int,\n",
        "    fmax: int,\n",
        "    top_db: Optional[int]\n",
        ") -> np.ndarray:\n",
        "    S = librosa.feature.melspectrogram(\n",
        "        y=wav,\n",
        "        sr=sr,\n",
        "        n_fft=n_fft,\n",
        "        hop_length=hop_length,\n",
        "        win_length=win_length,\n",
        "        n_mels=n_mels,\n",
        "        fmin=fmin,\n",
        "        fmax=fmax,\n",
        "        power=2.0,\n",
        "        center=True,\n",
        "        window=\"hann\"\n",
        "    )\n",
        "    S_db = librosa.power_to_db(S, ref=np.max)\n",
        "    if top_db is not None:\n",
        "        S_db = np.clip(S_db, a_min=S_db.max() - top_db, a_max=None)\n",
        "    # normalize to 0..1\n",
        "    S_min = S_db.min()\n",
        "    S_max = S_db.max()\n",
        "    S_norm = (S_db - S_min) / max(S_max - S_min, 1e-6)\n",
        "    return S_norm.astype(np.float32)\n",
        "\n",
        "\n",
        "def resize_spec(spec: np.ndarray, size: int) -> np.ndarray:\n",
        "    # spec shape: [n_mels, T]\n",
        "    # resize to [size, size] using torch interpolate for consistency\n",
        "    with torch.no_grad():\n",
        "        x = torch.from_numpy(spec).unsqueeze(0).unsqueeze(0)\n",
        "        x = F.interpolate(x, size=(size, size), mode=\"bilinear\", align_corners=False)\n",
        "        x = x.squeeze(0).squeeze(0)\n",
        "    return x.numpy().astype(np.float32)\n",
        "\n",
        "\n",
        "def spec_augment(spec: torch.Tensor, freq_masks: int, time_masks: int, freq_width: int, time_width: int) -> torch.Tensor:\n",
        "    # spec shape: [B, 1, H, W]\n",
        "    B, C, H, W = spec.shape\n",
        "    out = spec.clone()\n",
        "    for b in range(B):\n",
        "        for _ in range(freq_masks):\n",
        "            f = random.randint(0, freq_width)\n",
        "            f0 = random.randint(0, max(0, H - f))\n",
        "            out[b, :, f0:f0 + f, :] = 0.0\n",
        "        for _ in range(time_masks):\n",
        "            t = random.randint(0, time_width)\n",
        "            t0 = random.randint(0, max(0, W - t))\n",
        "            out[b, :, :, t0:t0 + t] = 0.0\n",
        "    return out"
      ],
      "metadata": {
        "id": "tjodKYVofqB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SleepEpochDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        csv_path: str,\n",
        "        cfg: Config,\n",
        "        augment: bool = False\n",
        "    ):\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if \"path\" not in df.columns or \"label\" not in df.columns:\n",
        "            raise ValueError(\"CSV must have columns path and label\")\n",
        "        self.paths = df[\"path\"].astype(str).tolist()\n",
        "        self.labels = df[\"label\"].astype(int).tolist()\n",
        "        self.cfg = cfg\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
        "        p = self.paths[idx]\n",
        "        y = self.labels[idx]\n",
        "        wav = load_audio(p, target_sr=self.cfg.sample_rate)\n",
        "        wav = ensure_length_seconds(wav, self.cfg.sample_rate, self.cfg.epoch_sec)\n",
        "\n",
        "        # simple waveform augmentation for training\n",
        "        if self.augment:\n",
        "            if random.random() < 0.25:\n",
        "                noise = np.random.randn(len(wav)).astype(np.float32) * 0.005\n",
        "                wav = wav + noise\n",
        "            if random.random() < 0.25:\n",
        "                gain = np.exp(np.random.uniform(-0.2, 0.2))\n",
        "                wav = wav * gain\n",
        "            if random.random() < 0.25:\n",
        "                shift = int(np.random.uniform(-0.1, 0.1) * len(wav))\n",
        "                wav = np.roll(wav, shift)\n",
        "\n",
        "        spec = wav_to_logmel(\n",
        "            wav=wav,\n",
        "            sr=self.cfg.sample_rate,\n",
        "            n_mels=self.cfg.n_mels,\n",
        "            n_fft=self.cfg.n_fft,\n",
        "            hop_length=self.cfg.hop_length,\n",
        "            win_length=self.cfg.win_length,\n",
        "            fmin=self.cfg.fmin,\n",
        "            fmax=self.cfg.fmax,\n",
        "            top_db=self.cfg.top_db\n",
        "        )\n",
        "        spec = resize_spec(spec, self.cfg.spec_size)  # [H, W] = [224, 224]\n",
        "        img = np.stack([spec, spec, spec], axis=0)  # [3, H, W]\n",
        "        x = torch.from_numpy(img).float()\n",
        "        y_t = torch.tensor(y).long()\n",
        "        return {\"x\": x, \"y\": y_t}"
      ],
      "metadata": {
        "id": "g4oSTvBzfqd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SleepViTClassifier(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.backbone = timm.create_model(\n",
        "            cfg.vit_name,\n",
        "            pretrained=True,\n",
        "            in_chans=3,\n",
        "            num_classes=cfg.num_classes,\n",
        "            drop_rate=cfg.vit_drop_rate,\n",
        "            drop_path_rate=cfg.vit_drop_path_rate\n",
        "        )\n",
        "        in_features = self.backbone.get_classifier().in_features\n",
        "        self.backbone.reset_classifier(num_classes=0, global_pool=\"avg\")\n",
        "        self.head = nn.Sequential(\n",
        "            nn.LayerNorm(in_features),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(in_features, cfg.num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x: [B, 3, 224, 224]\n",
        "        feats = self.backbone.forward_features(x)\n",
        "        if feats.ndim == 3:\n",
        "            feats = feats.mean(dim=1)\n",
        "        logits = self.head(feats)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class LabelSmoothingCE(nn.Module):\n",
        "    def __init__(self, smoothing: float = 0.0):\n",
        "        super().__init__()\n",
        "        assert 0.0 <= smoothing < 1.0\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, logits: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "        n_classes = logits.size(-1)\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(log_probs)\n",
        "            true_dist.fill_(self.smoothing / (n_classes - 1))\n",
        "            true_dist.scatter_(1, target.unsqueeze(1), 1.0 - self.smoothing)\n",
        "        loss = torch.mean(torch.sum(-true_dist * log_probs, dim=-1))\n",
        "        return loss\n",
        "\n",
        "def do_mixup(x: torch.Tensor, y: torch.Tensor, alpha: float) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    if alpha <= 0.0:\n",
        "        return x, y, None\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    batch_size = x.size(0)\n",
        "    index = torch.randperm(batch_size, device=x.device)\n",
        "    mixed_x = lam * x + (1.0 - lam) * x[index, :]\n",
        "    y_a = y\n",
        "    y_b = y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1.0 - lam) * criterion(pred, y_b)\n"
      ],
      "metadata": {
        "id": "2iotTgMHfywK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    scheduler,\n",
        "    device: torch.device,\n",
        "    criterion,\n",
        "    cfg: Config\n",
        ") -> Tuple[float, float]:\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch in loader:\n",
        "        x = batch[\"x\"].to(device, non_blocking=True)\n",
        "        y = batch[\"y\"].to(device, non_blocking=True)\n",
        "\n",
        "        if cfg.spec_aug_freq_masks > 0 or cfg.spec_aug_time_masks > 0:\n",
        "            x = spec_augment(\n",
        "                x,\n",
        "                cfg.spec_aug_freq_masks,\n",
        "                cfg.spec_aug_time_masks,\n",
        "                cfg.spec_aug_freq_width,\n",
        "                cfg.spec_aug_time_width\n",
        "            )\n",
        "\n",
        "        if cfg.mixup_alpha > 0.0:\n",
        "            x, y_a, y_b, lam = do_mixup(x, y, cfg.mixup_alpha)\n",
        "            logits = model(x)\n",
        "            loss = mixup_criterion(criterion, logits, y_a, y_b, lam)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            # accuracy approximate with hard labels y_a\n",
        "            correct = (preds == y_a).sum().item()\n",
        "        else:\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct = (preds == y).sum().item()\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
        "        optimizer.step()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        total_correct += correct\n",
        "        total += x.size(0)\n",
        "\n",
        "    avg_loss = total_loss / max(total, 1)\n",
        "    acc = total_correct / max(total, 1)\n",
        "    return avg_loss, acc\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    device: torch.device,\n",
        "    cfg: Config\n",
        ") -> Tuple[float, float, np.ndarray, List[int], List[int]]:\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    for batch in loader:\n",
        "        x = batch[\"x\"].to(device, non_blocking=True)\n",
        "        y = batch[\"y\"].to(device, non_blocking=True)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        total += x.size(0)\n",
        "        all_preds.extend(preds.cpu().tolist())\n",
        "        all_targets.extend(y.cpu().tolist())\n",
        "\n",
        "    avg_loss = total_loss / max(total, 1)\n",
        "    acc = np.mean(np.array(all_preds) == np.array(all_targets))\n",
        "    cm = confusion_matrix(all_targets, all_preds, labels=list(range(cfg.num_classes)))\n",
        "    return avg_loss, acc, cm, all_preds, all_targets\n",
        "\n",
        "\n",
        "def compute_class_weights(labels: List[int], num_classes: int) -> torch.Tensor:\n",
        "    counts = np.bincount(labels, minlength=num_classes).astype(np.float32)\n",
        "    inv = 1.0 / np.maximum(counts, 1.0)\n",
        "    weights = inv / inv.sum() * num_classes\n",
        "    return torch.tensor(weights, dtype=torch.float32)\n",
        "\n",
        "\n",
        "def make_optimizer(model: nn.Module, cfg: Config) -> torch.optim.Optimizer:\n",
        "    return torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "\n",
        "\n",
        "def make_scheduler(optimizer: torch.optim.Optimizer, cfg: Config, steps_per_epoch: int):\n",
        "    total_steps = max(1, cfg.epochs) * max(1, steps_per_epoch)\n",
        "    warmup_steps = cfg.warmup_epochs * max(1, steps_per_epoch)\n",
        "    def lr_lambda(step):\n",
        "        if step < warmup_steps:\n",
        "            return float(step + 1) / float(max(1, warmup_steps))\n",
        "        progress = float(step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "        return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
        "\n",
        "\n",
        "def save_checkpoint(model: nn.Module, path: str) -> None:\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    torch.save({\"state_dict\": model.state_dict()}, path)\n",
        "\n",
        "\n",
        "def load_checkpoint(model: nn.Module, path: str, device: torch.device) -> None:\n",
        "    ckpt = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(ckpt[\"state_dict\"], strict=True)"
      ],
      "metadata": {
        "id": "9xtjA6DLf2g2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_main(args):\n",
        "    cfg = Config()\n",
        "    cfg.epochs = args.epochs\n",
        "    cfg.train_batch_size = args.train_bs\n",
        "    cfg.val_batch_size = args.val_bs\n",
        "    cfg.vit_name = args.vit\n",
        "    cfg.num_classes = args.num_classes\n",
        "    cfg.class_names = DEFAULT_CLASS_NAMES_4 if cfg.num_classes == 4 else DEFAULT_CLASS_NAMES_5\n",
        "\n",
        "    set_seed(cfg.seed)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    train_ds = SleepEpochDataset(args.train_csv, cfg, augment=True)\n",
        "    val_ds = SleepEpochDataset(args.val_csv, cfg, augment=False)\n",
        "\n",
        "    # optional class weights\n",
        "    cw = compute_class_weights(train_ds.labels, num_classes=cfg.num_classes).to(device)\n",
        "    criterion = LabelSmoothingCE(smoothing=cfg.label_smoothing)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=cfg.train_batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=cfg.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=False\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=cfg.val_batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=cfg.num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=False\n",
        "    )\n",
        "\n",
        "    model = SleepViTClassifier(cfg).to(device)\n",
        "\n",
        "    # freeze backbone for warmup if desired\n",
        "    if args.freeze_backbone_epochs > 0:\n",
        "        for p in model.backbone.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    optimizer = make_optimizer(model, cfg)\n",
        "    scheduler = make_scheduler(optimizer, cfg, steps_per_epoch=len(train_loader))\n",
        "\n",
        "    best_acc = 0.0\n",
        "    best_path = os.path.join(args.out_dir, \"best.pt\")\n",
        "    os.makedirs(args.out_dir, exist_ok=True)\n",
        "\n",
        "    global_step = 0\n",
        "    for epoch in range(cfg.epochs):\n",
        "        if epoch == args.freeze_backbone_epochs:\n",
        "            for p in model.backbone.parameters():\n",
        "                p.requires_grad = True\n",
        "            print(\"Backbone unfrozen\")\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0\n",
        "        running_total = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            x = batch[\"x\"].to(device, non_blocking=True)\n",
        "            y = batch[\"y\"].to(device, non_blocking=True)\n",
        "\n",
        "            if cfg.spec_aug_freq_masks > 0 or cfg.spec_aug_time_masks > 0:\n",
        "                x = spec_augment(\n",
        "                    x,\n",
        "                    cfg.spec_aug_freq_masks,\n",
        "                    cfg.spec_aug_time_masks,\n",
        "                    cfg.spec_aug_freq_width,\n",
        "                    cfg.spec_aug_time_width\n",
        "                )\n",
        "\n",
        "            if cfg.mixup_alpha > 0.0:\n",
        "                x, y_a, y_b, lam = do_mixup(x, y, cfg.mixup_alpha)\n",
        "                logits = model(x)\n",
        "                loss = mixup_criterion(criterion, logits, y_a, y_b, lam)\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                correct = (preds == y_a).sum().item()\n",
        "            else:\n",
        "                logits = model(x)\n",
        "                # weighted CE with smoothing by wrapping\n",
        "                ce = nn.CrossEntropyLoss(weight=cw)\n",
        "                smoothed_loss = ce(logits, y) * (1.0 - cfg.label_smoothing) + \\\n",
        "                                LabelSmoothingCE(cfg.label_smoothing)(logits, y) * cfg.label_smoothing\n",
        "                loss = smoothed_loss\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                correct = (preds == y).sum().item()\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            running_loss += loss.item() * x.size(0)\n",
        "            running_correct += correct\n",
        "            running_total += x.size(0)\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        train_loss = running_loss / max(running_total, 1)\n",
        "        train_acc = running_correct / max(running_total, 1)\n",
        "\n",
        "        val_loss, val_acc, cm, preds, targets = evaluate(model, val_loader, device, cfg)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{cfg.epochs} | \"\n",
        "              f\"train_loss {train_loss:.4f} acc {train_acc:.4f} | \"\n",
        "              f\"val_loss {val_loss:.4f} acc {val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            save_checkpoint(model, best_path)\n",
        "            print(f\"Saved new best to {best_path} with acc {best_acc:.4f}\")\n",
        "\n",
        "        # optional early stop\n",
        "        if args.early_stop_acc is not None and val_acc >= args.early_stop_acc:\n",
        "            print(\"Early stopping because target val acc reached\")\n",
        "            break\n",
        "\n",
        "    # Final evaluation on the best model\n",
        "    load_checkpoint(model, best_path, device)\n",
        "    val_loss, val_acc, cm, preds, targets = evaluate(model, val_loader, device, cfg)\n",
        "    print(\"Best model validation results:\")\n",
        "    print(f\"val_loss {val_loss:.4f} val_acc {val_acc:.4f}\")\n",
        "    print(\"Confusion matrix rows true, cols pred:\")\n",
        "    print(cm)\n",
        "    print(\"Balanced accuracy:\", balanced_accuracy_score(targets, preds))\n",
        "    print(classification_report(targets, preds, target_names=cfg.class_names))"
      ],
      "metadata": {
        "id": "NkUlBJyMf5s5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}